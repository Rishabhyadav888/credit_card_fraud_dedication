{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "mDgbUHAGgjLW",
        "HhfV-JJviCcP",
        "Y3lxredqlCYt",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rishabhyadav888/credit_card_fraud_dedication/blob/main/Credit_card_fraud_dedicution_in_Taiwan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - \n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Classification\n",
        "##### **Contribution**    - Individual\n",
        "##### **Team Member 1 -**Rishabh kumar yadav\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The project aimed to predict the probability of default for Taiwanese credit card clients to minimize losses for banks and credit card companies. The classification problem involved predicting if a client would default or not in the next month. The study highlighted the importance of risk management and demonstrated how machine learning algorithms can improve predictive accuracy.\n",
        "\n",
        "In the data preprocessing step, the ID column was dropped, and the numeric columns were converted to the integer data type. The values of the categorical columns were also changed from integer to string data type for better understanding. Some columns were renamed to make them more meaningful. Additionally, a new feature called \"total due\" was added, which represented the total amount left for payment. These steps were taken to improve the quality and usability of the data for machine learning analysis.\n",
        "\n",
        "In the data visualization step, univariate analysis, bivariate analysis, and multivariate analysis were performed to understand the relationships between variables. The correlation heatmap showed that bill months had multicollinearity with VIF values greater than 20. To address this issue, the columns were added together, and a new column called \"total bill\" was created. This step helped to improve the accuracy of the machine learning algorithm by reducing the impact of multicollinearity on the analysis.\n",
        "\n",
        "In the feature engineering step, category encoding was performed on several categorical columns. For sex, level encoding was used, and for marriage and education, one-hot encoding was used. In the feature selection step, recursive feature selection was employed, which involved the backward elimination of features based on their coefficient values by running different combinations. The data scaling was performed using the standard scalar. To handle the imbalanced data of the dependent variable, the SMOTE oversampling method was used. Finally, the data was split into training and testing sets using the train-test split method. These steps were taken to improve the quality of the data and prepare it for machine learning analysis.\n",
        "\n",
        "In the ML model implementation step, various algorithms were used to build the predictive model, including logistic regression, decision tree, K-nearest neighbor classifier, random forest, and XGBoost classifier. Evaluation metrics such as accuracy score, ROC-AUC score, and confusion matrix were used to assess the performance of the models. These metrics helped to determine the accuracy and reliability of the model and were used to select the best performing model for the final analysis.\n",
        "\n",
        "Identifying credit card transactions that are likely to default on payment is crucial for businesses to minimize financial losses, protect their credit score, avoid legal issues, and maintain a good reputation. This type of problem requires minimizing false negatives to accurately identify transactions that are likely to default. The K-nearest neighbor classifier had the highest recall score of 0.92, indicating that it is the most suitable model for predicting credit card defaults. Therefore, it can be used for the final prediction to help businesses prevent financial losses and minimize risk.\n",
        "\n",
        "In conclusion, the project demonstrated the importance of risk management and how machine learning algorithms can be used to improve predictive accuracy for credit card default prediction in Taiwan. Through various steps of data preprocessing, visualization, feature engineering, selection, and ML model implementation, the project aimed to prepare the data for analysis and select the best performing model for the final prediction. The K-nearest neighbor classifier had the highest recall score, indicating its suitability for predicting credit card defaults, and can be used to help businesses minimize financial losses and risk."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "https://github.com/Rishabhyadav888/credit_card_fraud_dedication"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " \n",
        "*   Certain Cases of Customers default on Payments in Taiwan.\n",
        "*   From a Risk Management Perspective a Bank/Credit Card Company is more interested in minimizing their losses towards a particular customer.\n",
        "*  Goal: To compute the predictive accuracy of probability of default for a Taiwanese Credit Card Client.\n",
        "*Problem Analysis - Classify Probability of default for next month: 1 as \"Default\" and o as \"Not Default\".\n",
        "\n"
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import xgboost as xg\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "import warnings; warnings.simplefilter('ignore')\n"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# connect to google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "S4UQJJorkDn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "path='/content/drive/MyDrive/Capstone Project/Credit Card fraud/'\n",
        "df= pd.read_excel(path+'default of credit card clients.xls')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "headers=df.iloc[0]\n",
        "df  = pd.DataFrame(df.values[1:], columns=headers)"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# First 5 rows of dataset\n",
        "df.head()"
      ],
      "metadata": {
        "id": "F3Ro5i-CkTCr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "df.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "len(df[df.duplicated()])"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is no NAN/NULL values in our dataset,So we dont have to impute any record."
      ],
      "metadata": {
        "id": "UNXrbI5PrvoY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Our dataset contains 30000 rows with 23 input variable and 1 target column.\n",
        "* All the columns are object type.some of the feature need to be converted into int or float type.\n",
        "* There are variables that need to be converted to categories like(sex,education,marraige)"
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "df.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description "
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* ID: ID of each client\n",
        "* LIMIT_BAL: Amount of given credit in NT dollars (includes individual and family/supplementary credit\n",
        "* SEX: Gender (1=male, 2=female)\n",
        "* EDUCATION: (1=graduate school, 2=university, 3=high school, 4=others, 5=unknown, 6=unknown)\n",
        "* MARRIAGE: Marital status (1=married, 2=single, 3=others)\n",
        "* AGE: Age in years\n",
        "* PAY_0: Repayment status in September, 2005 (-1=pay duly, 1=payment delay for one month, 2=payment delay for two months, â€¦ 8=payment delay for eight months, 9=payment delay for nine months and above)\n",
        "* PAY_2: Repayment status in August, 2005 (scale same as above)\n",
        "* PAY_3: Repayment status in July, 2005 (scale same as above)\n",
        "* PAY_4: Repayment status in June, 2005 (scale same as above)\n",
        "* PAY_5: Repayment status in May, 2005 (scale same as above)\n",
        "* PAY_6: Repayment status in April, 2005 (scale same as above)\n",
        "* BILL_AMT1: Amount of bill statement in September, 2005 (NT dollar)\n",
        "* BILL_AMT2: Amount of bill statement in August, 2005 (NT dollar)\n",
        "* BILL_AMT3: Amount of bill statement in July, 2005 (NT dollar)\n",
        "* BILL_AMT4: Amount of bill statement in June, 2005 (NT dollar)\n",
        "* BILL_AMT5: Amount of bill statement in May, 2005 (NT dollar)\n",
        "* BILL_AMT6: Amount of bill statement in April, 2005 (NT dollar)\n",
        "* PAY_AMT1: Amount of previous payment in September, 2005 (NT dollar)\n",
        "* PAY_AMT2: Amount of previous payment in August, 2005 (NT dollar)\n",
        "* PAY_AMT3: Amount of previous payment in July, 2005 (NT dollar)\n",
        "* PAY_AMT4: Amount of previous payment in June, 2005 (NT dollar)\n",
        "* PAY_AMT5: Amount of previous payment in May, 2005 (NT dollar)\n",
        "* PAY_AMT6: Amount of previous payment in April, 2005 (NT dollar)\n",
        "* default.payment.next.month: Default payment (1=yes, 0=no)\n",
        "Inspiration"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "label_colum=['SEX', 'EDUCATION', 'MARRIAGE', 'AGE','default payment next month','PAY_0']\n",
        "list_columns=list(label_colum)\n",
        "for colm in list_columns:\n",
        " print(f\"Feature unique values for each variable:{colm} {df[colm].unique()}\")\n"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Deleted the ID column from df\n",
        "df.drop('ID',axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "cXkU0tZjAnYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converted the numeric columns to int dtype\n",
        "categorical_colum=['SEX', 'EDUCATION', 'MARRIAGE']\n",
        "numeric_colum=df.columns.drop(categorical_colum)\n",
        "df[numeric_colum] = df[numeric_colum].apply(pd.to_numeric)"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data type of each variable\n",
        "df.dtypes"
      ],
      "metadata": {
        "id": "uwwCo35V97KB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe().T"
      ],
      "metadata": {
        "id": "u6sCPemSFCuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converted the numeric value to categorical\n",
        "df.replace({'SEX': {1 : 'Male', 2 : 'Female'}, 'EDUCATION' : {1 : 'graduate school', 2 : 'university', 3 : 'high school', 4 : 'others'}, 'MARRIAGE' : {1 : 'married', 2 : 'single', 3 : 'others'}}, inplace = True)"
      ],
      "metadata": {
        "id": "taPtBYGtsX6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#renaming columns \n",
        "\n",
        "df.rename(columns={'PAY_0':'PAY_SEPT','PAY_2':'PAY_AUG','PAY_3':'PAY_JUL','PAY_4':'PAY_JUN','PAY_5':'PAY_MAY','PAY_6':'PAY_APR'},inplace=True)\n",
        "df.rename(columns={'BILL_AMT1':'BILL_AMT_SEPT','BILL_AMT2':'BILL_AMT_AUG','BILL_AMT3':'BILL_AMT_JUL','BILL_AMT4':'BILL_AMT_JUN','BILL_AMT5':'BILL_AMT_MAY','BILL_AMT6':'BILL_AMT_APR'}, inplace = True)\n",
        "df.rename(columns={'PAY_AMT1':'PAY_AMT_SEPT','PAY_AMT2':'PAY_AMT_AUG','PAY_AMT3':'PAY_AMT_JUL','PAY_AMT4':'PAY_AMT_JUN','PAY_AMT5':'PAY_AMT_MAY','PAY_AMT6':'PAY_AMT_APR'},inplace=True)\n",
        "df.rename(columns={'default payment next month':'default'},inplace=True)"
      ],
      "metadata": {
        "id": "Q-5BLgXzJAna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "cO0WE3x0MB0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add new feature (total due)\n",
        "df['due_amount'] = (df['BILL_AMT_APR']+df['BILL_AMT_MAY']+df['BILL_AMT_JUN']+df['BILL_AMT_JUL']+df['BILL_AMT_SEPT'])-(df['PAY_AMT_APR']+df['PAY_AMT_MAY']+df['PAY_AMT_JUN']+df['PAY_AMT_JUL']+df['PAY_AMT_AUG']+df['PAY_AMT_SEPT'])"
      ],
      "metadata": {
        "id": "A5-5ujMIE9yU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Drop the ID column\n",
        "* Converted the numeric columns to int dtype.\n",
        "* Changed the values of categorical column from int to str type.\n",
        "* Renamed few columns to make it more understandable.\n",
        "* Added new feature total due - (total amount left for payment)"
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    }
  ]
}